#Sprawozdanie DevOps - lab12
### Daniel Klata - ITE-GCL03

## Zadanie

Zadanie jest kontynuacjÄ… wdraÅ¼ania na zarzÄ…dzalne kontenery w Kubernetes.

PolegaÅ‚o na zmianie pliku wdroÅ¼eniowego skonstruowanego w ramach poprzedniego laboratorium, zbadaniu zachowania kubernetesa podczas zmiany iloÅ›ci replik, stworzeniu nowej wersji obrazu, ktÃ³rej wdroÅ¼enie ma siÄ™ zakoÅ„czyÄ‡ katastrofÄ… wewnÄ…trz kontenerÃ³w oraz stworzenie mechanizmu kontroli wdroÅ¼enia, ktÃ³ry sprawdzi czy wdroÅ¼enie powiodÅ‚o siÄ™ w krÃ³cej niÅ¼ 60 sekund.

## Wykonanie

Plik .yaml z poprzednich zajÄ™Ä‡, ktÃ³ry wykorzystano do modyfikacji:


	apiVersion: apps/v1
	kind: Deployment
	metadata:
		name: todo-deployment
	spec:
	selector:
		matchLabels:
		app: todo
	replicas: 2
	template:
		metadata:
		labels:
			app: todo
		spec:
		containers:
		- name: todo
			image: quay.io/danieloh30/todo-app:1.0
			ports:
			- containerPort: 80

Aby przeprowadziÄ‡ dalsze badania, zwyczajnie zmieniano iloÅ›Ä‡ replik w powyÅ¼szym pliku:

`replicas: 2` - > `replicas: 4` / `6` / `1` / `0`

4 repliki - Przerobiono plik wdroÅ¼enia w nastÄ™pujÄ…cy sposÃ³b:

![](images/yaml_with_4replicas.png)

WdroÅ¼ono aplikacjÄ™ z pliku komendÄ…
`kubectl apply -f pod_todo.yaml`

![](images/4_replicas_apply.png)

Po wykonaniu komendy, na dashboardzie kubernetesa moÅ¼emy zauwaÅ¼yÄ‡, Å¼e utworzyÅ‚ siÄ™ deployment `todo-deployment` posiadajÄ…cy 4 pody replik.

![](images/kube_dashboard_4replicas.png)

Sprawdzono poprawnoÅ›Ä‡ wdroÅ¼enia za pomocÄ… komendy `kubectl rollout status deployment todo-deployment`

![](images/successful_deployment_4replicas.png)

NastÄ™pnie zmodyfikowano plik .yaml w analogiczny sposÃ³b jak poprzednio, lecz ustawiono iloÅ›Ä‡ replik na 6. Po ponownym wykonaniu `kubectl apply` moÅ¼na zauwaÅ¼yÄ‡, Å¼e wiadomoÅ›Ä‡ zmieniÅ‚a siÄ™ z `deployment created`, na `deployment configured`

![](images/deployment_configured.png)

W dashboardzie moÅ¼na zauwaÅ¼yÄ‡ utworzone dodatkowe 2 pody:

![](images/6_replicas.png)

Wykonano wszystkie powyÅ¼sze kroki ponownie dla pojedynczej repliki, jak widaÄ‡ wdroÅ¼enie todo ma tylko jednego poda:

![](images/1_replica.png)

Oraz dla 0 replik, w tym przypadku widaÄ‡, Å¼e deployment istnieje, lecz posiada 0/0 podÃ³w, replica set podobnie ma 0 podÃ³w:

![](images/0_replicas.png)

NastÄ™pnie stworzono plik dockerfile, ktÃ³rego zadaniem jest wyrzucenie bÅ‚Ä™du w kontenerze, stworzono z niego obraz oraz otagowano jako `error`

	FROM nginx:latest
	RUN echo 'Dockerfile ktÃ³ry ma siÄ™ wywaliÄ‡ ğŸ‰'
	ENTRYPOINT echo ["exit", 1]

![](images/bad_dockerfile.png)

Zaktualizowano plik wdroÅ¼enia .yaml, tak aby korzystaÅ‚ z zepsutego Dockerfile'a

		containers:
		- name: todo
			image: error
			ports:
			- containerPort: 80

A nastÄ™pnie wdroÅ¼ono zmiany komendÄ… `kubectl apply -f pod_todo.yaml`. Zmiany w dashboardzie pokazujÄ…, Å¼e obraz wprowadzony na nasze pody powoduje errory:

![](images/dashboard_with_bad_image.png)

Aby naprawiÄ‡ sytuacje z niedziaÅ‚ajacymi podami, skorzystano z komend:
`kubectl rollout history deployment todo-deployment` - ktÃ³ra pokaÅ¼e nam historiÄ™ zmian
`kubectl rollout undo deployment todo-deployment` - ktÃ³ra cofnie zmiany na podach do poprzedniej, dziaÅ‚ajÄ…cej wersji

![](images/rollout_history_and_undo.png)

Jak widaÄ‡ na dashboardzie, niedziaÅ‚ajace pody zostaÅ‚y przywrÃ³cone do stabilnego stanu po uÅ¼yciu komendy `undo`:

![](images/after_undo.png)

NastÄ™pnie sprawdzono szczegÃ³Å‚y deploymentu komendÄ… `kubectl describe deployment`

![](images/describe_deployment.png)

Na koÅ„cu stworzono system kontroli wdroÅ¼enia, ktÃ³ry miaÅ‚ sprawdziÄ‡ poprawnoÅ›Ä‡ wdroÅ¼enia. (Czy udaÅ‚o siÄ™ ono w mniej niÅ¼ 60 sekund):

	#!/bin/bash
	minikube kubectl -- apply -f pod_todo.yaml
	timeout 60 minikube kubectl -- rollout status deployment/todo-deployment
	
	if [ "$?" -eq 0 ]
	then
		echo "SUCCESS - poprawnie wdroÅ¼ono aplikacjÄ™ z pliku yaml ğŸ‰"
	else
		echo "ERROR - wdroÅ¼enie zajÄ™Å‚o zbyt dÅ‚ugo ğŸ˜­"
	fi

DziaÅ‚anie skryptu:

![](images/deployment_control_script.png)

Strategie wdroÅ¼eÅ„:

`Rolling deployment`â€” Jest to strategia wdroÅ¼eniowa, ktÃ³ra zamienia wszystkie pody dziaÅ‚ajÄ…ce na starej wersji aplikacji z nowÄ… wersjÄ…. Zamiana wykonywana jest jeden po drugim, przez co klaster nie ma Å¼adnego downtime'u.
`Recreate`â€” Strategia wdroÅ¼eniowa, ktÃ³ra niszczy wszystkie pody i zastÄ™puje je nowÄ… wersjÄ…. 
`Canary deployment`â€” Jest to strategia ktÃ³ra ma podejÅ›cie progresywnego dostarczania, gdzie jedna z wersji aplikacji jest udostÄ™pniana wiÄ™kszoÅ›ci uÅ¼ytkownikÃ³w, a nowsza wersja jest serwowana mniejszej bazie test userÃ³w, jeÅ›li testowy deployment dziaÅ‚a prawidÅ‚owo, jest on udostÄ™pniany wiÄ™kszej iloÅ›ci uÅ¼ytkownikÃ³w.

W powyÅ¼szym projekcie zastosowano strategiÄ™ rolling deployment, jest ona defaultowÄ… strategiÄ… uÅ¼ywanÄ… przez kubernetesa.

Aby zastosowaÄ‡ strategiÄ™ recreate naleÅ¼y zdefiniowaÄ‡ jÄ… wewnÄ…trz pliku wdroÅ¼eniowego:

	...
	apiVersion: app/v1
	...
	spec:
		replicas:8
		strategy:
			type: Recreate
		template:
		...
	EOF

Problem ze strategiÄ… recreate jest taki, Å¼e moÅ¼e ona powodowaÄ‡ downtime, gdyÅ¼ stare pody sÄ… usuwane zanim upewnimy siÄ™ Å¼e pody z nowÄ… wersjÄ… aplikacji zostaÅ‚y wdroÅ¼one.

